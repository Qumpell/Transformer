{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6316f2e",
   "metadata": {},
   "source": [
    "### Mateusz Kantorski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a80869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from seqeval.metrics import classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8278f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    token_lists = []\n",
    "    label_lists = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or '\\t' not in line:\n",
    "                continue\n",
    "            label_part, token_part = line.split('\\t')\n",
    "            labels = label_part.strip().split()\n",
    "            tokens = token_part.strip().split()\n",
    "            if len(tokens) != len(labels):\n",
    "                print(\"Warning: mismatch in lengths\")\n",
    "                continue\n",
    "            token_lists.append(tokens)\n",
    "            label_lists.append(labels)\n",
    "    return token_lists, label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc4407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8436a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(tokens, preds):\n",
    "    aligned_labels = ['O'] * len(tokens)\n",
    "\n",
    "    for ent in preds:\n",
    "        start, end, label = ent['start'], ent['end'], ent['entity_group']\n",
    "        sub_text = tokenizer.convert_ids_to_tokens(tokenizer.encode(ent['word'], add_special_tokens=False))\n",
    "        words = ent['word'].split()\n",
    "        ent_tokens = tokenizer.tokenize(ent['word'])\n",
    "        word_idx = 0\n",
    "        for i, token in enumerate(tokens):\n",
    "            if ' '.join(tokens[i:i+len(words)]) == ent['word']:\n",
    "                aligned_labels[i] = f\"B-{label}\"\n",
    "                for j in range(1, len(words)):\n",
    "                    if i + j < len(aligned_labels):\n",
    "                        aligned_labels[i + j] = f\"I-{label}\"\n",
    "                break\n",
    "    return aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70739c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.96      0.51      0.67      7139\n",
      "        MISC       0.91      0.43      0.58      3436\n",
      "         ORG       0.89      0.55      0.68      6317\n",
      "         PER       0.72      0.44      0.54      6600\n",
      "\n",
      "   micro avg       0.86      0.49      0.63     23492\n",
      "   macro avg       0.87      0.48      0.62     23492\n",
      "weighted avg       0.87      0.49      0.63     23492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "tokens_list, labels_list = load_data(\"train/train.tsv\")\n",
    "\n",
    "for tokens, true in zip(tokens_list, labels_list):\n",
    "    preds = nlp(' '.join(tokens))\n",
    "    pred_bio = align_predictions(tokens, preds)\n",
    "\n",
    "    if len(pred_bio) != len(true):\n",
    "        print(\"Length mismatch! Skipping.\")\n",
    "        continue\n",
    "\n",
    "    true_labels.append(true)\n",
    "    pred_labels.append(pred_bio)\n",
    "\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
